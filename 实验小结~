1. 对于高斯分布生成的数据,一般来说隐藏单元数的重要性要大于层数, 也就是说, 隐藏单元越多, 越容易对数据进行分类.
2. 神经网络聚类如果随机的赋予初始标记的话,结果往往不好,我想这主要是归结于其极强的泛化能力,但是如果适当的给它一些初始信息的话,它能够很好的完成聚类. 也就是说它对初始情况极为敏感.
3. 现阶段采用的聚类方法是先挑几个典型点给神经网络做,然后套用semi-supervised的框架给它做,目前在toy dataset上能与kmeans抗衡
4. 神经网络的强大在于对空间的转化能力，即将一个低维的特征扩展到高维或将一个高维的特征压缩到低维使其能够满足一定的性质，利于有监督学习，但是无监督学习需要考虑到数据之间的两两关系，这一点如何在神经网络中体现呢，神经网络甚至不知道什么是对的什么是错的，它只能盲目的优化达到某个局部最优值
